#!/usr/bin/env ruby

$LOAD_PATH.unshift(File.join(File.dirname(__FILE__), '..'))         # Look in the root directory for .rb files
$LOAD_PATH.unshift(File.join(File.dirname(__FILE__), '..', 'lib'))  # Look in the lib directory for .rb files

require 'rubygems'
require "bundler/setup"
require 'trollop'
require 'indexer'

# Define the collections that this script knows how to harvest per yml files in the config/collections directory
# @return Array
def collections
	config_dir = File.join(File.dirname(__FILE__), '..', 'config', 'collections')
	files = Dir.glob("#{config_dir}/*.yml")
	files.map! {|x| File.basename(x, ".yml") }
end

# use Trollop to declare options and help text.
@opts = Trollop::options do
  version "indexer v0.2.0 (c) 2012-2014 Stanford University http://searchworks.stanford.edu"
  banner <<-EOM
  The indexer script harvests records from SearchWorks OAI-PMH Provider,
  maps them to Solr document hashes appropriate for SearchWorks, and writes them to Solr
  Usage:
    ./index [options] 
  where [options] are:
  EOM
    
  opt :collection, 
    "Index a given collection. Possible values are #{collections.sort}",
    :default => nil,
    :short => 'c',
    :type => String,
    :multi => true
  opt :nocommit,
    "Index the collection but don't commit",
    :default => nil,
    :short => 'n'
  opt :all, "Index all collections"
#  opt :set, 
#    "Harvest results from the given set",
#    :default => nil,
#    :short => 's',
#    :type => String
#  opt :from, 
#    "Filter results starting from the given date",
#    :default => nil,
#    :short => 'f',
#    :type => String
#  opt :until,
#    "Filter results until the given date",
#    :default => nil,
#    :short => 'u',
#    :type => String
end

# Trollop::die :collection, "must be a known collection. Possible values are: #{collections.inspect} You entered #{@opts[:collection]}" unless collections.include?@opts[:collection]

# [:from, :until].each do |d| 
#   if opts[d]
#     begin
#       opts[d] = Time.parse opts[d]
#     rescue Exception => e
#       puts "Error, option --#{d.to_s} is not a valid date"
#       exit(1)
#     end
#   end
# end

# If no set is specified, harvest the sets from the config file
# if opts[:set]
#   SearchWorksOaiHarvester::Harvester.new(SearchWorksOaiHarvester.oai_client, SearchWorksOaiHarvester.solr_client, opts).harvest
# else
#   SearchWorksOaiHarvester.logger.info "No set specified. Harvesting sets from config file."
#   SearchWorksOaiHarvester.config.sets.each do |s|
#     SearchWorksOaiHarvester.logger.info "Harvesting #{s[0]}"
#     opts[:set] = s[1]
#     SearchWorksOaiHarvester::Harvester.new(SearchWorksOaiHarvester.oai_client, SearchWorksOaiHarvester.solr_client, opts).harvest
#   end
# end
# SearchWorksOaiHarvester.logger.info 'Commiting to Solr'
# SearchWorksOaiHarvester.solr_client.commit

def time
  start = Time.now
  yield
  elapsed = Time.now - start
  puts "This set took #{elapsed} seconds to run."
end

# Get all of the specified collections (from the command line) into an Array
@collections = []
if @opts[:collection].instance_of?Array 
  @collections = @opts[:collection] 
else 
  @collections << @opts[:collection]
end

# process each collection from the command line
@collections.each do |coll|
  solr_config_path = File.join(File.dirname(__FILE__), "..", "config", "solr.yml")
  config_yml_path = File.join(File.dirname(__FILE__), "..", "config", "collections", "#{coll}.yml")
  @indexer = Indexer.new(config_yml_path, solr_config_path)
  puts "Indexing #{coll} into Solr server #{Indexer.config[:solr][:url]}"
  puts "Logging output to #{Indexer.config[:log_dir]}/#{Indexer.config[:log_name]}"
  time do
    if @indexer.collection_is_mergable?
      puts 'A collection record merge will happen!'
    end
    @indexer.harvest_and_index @opts[:nocommit]
  end
end

